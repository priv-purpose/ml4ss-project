{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title\n",
    "## A. Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import _pickle as pickle\n",
    "\n",
    "from Components import Comment, Post, POSPost, POSComment\n",
    "from Models import MyDictionary, MyTfidf, MyLda\n",
    "from helper import load_v1, load_v2\n",
    "from eval import load_eval_sets, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Loaded v1: 18570\n",
      "- Loaded v2: 18570\n"
     ]
    }
   ],
   "source": [
    "v1, v2 = load_v1(), load_v2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Loaded 4 evaluation sets\n"
     ]
    }
   ],
   "source": [
    "eval_sets = load_eval_sets() # Evaluation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "CREATE_NEW = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Training Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionaries\n",
    "if CREATE_NEW:\n",
    "    dictionary_1_f = MyDictionary(v2, title_weight=1, use_comments=False)\n",
    "    dictionary_1_t = MyDictionary(v2, title_weight=1, use_comments=True)\n",
    "\n",
    "    pickle.dump(dictionary_1_f, open(\"models/dictionary_1_f\", \"wb+\"))\n",
    "    pickle.dump(dictionary_1_t, open(\"models/dictionary_1_t\", \"wb+\"))\n",
    "\n",
    "# Load dictionaries\n",
    "dictionary_1_f = pickle.load(open(\"models/dictionary_1_f\", \"rb\"))\n",
    "dictionary_1_t = pickle.load(open(\"models/dictionary_1_t\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF\n",
    "Training these models without looking at comment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tf-idf\n",
    "if CREATE_NEW:\n",
    "    tfidf_ntc = MyTfidf(dictionary_1_f, smartirs='ntc')\n",
    "    tfidf_ltc = MyTfidf(dictionary_1_f, smartirs='ltc')\n",
    "    tfidf_lpc = MyTfidf(dictionary_1_f, smartirs='lpc')\n",
    "    \n",
    "    pickle.dump(tfidf_ntc, open(\"models/tfidf_ntc\", \"wb+\"))\n",
    "    pickle.dump(tfidf_ltc, open(\"models/tfidf_ltc\", \"wb+\"))\n",
    "    pickle.dump(tfidf_lpc, open(\"models/tfidf_lpc\", \"wb+\"))\n",
    "\n",
    "tfidf_ntc = pickle.load(open(\"models/tfidf_ntc\", \"rb\"))\n",
    "tfidf_ltc = pickle.load(open(\"models/tfidf_ltc\", \"rb\"))\n",
    "tfidf_lpc = pickle.load(open(\"models/tfidf_lpc\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_ntc.cluster(1000)\n",
    "pickle.dump(tfidf_ntc, open(\"models/tfidf_ntc\", \"wb+\"))\n",
    "# for id in tfidf_ntc.cluster2id[9]:\n",
    "#     print(v2[id].title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "손놓충 자전거, 퀴어 퍼레이드, 전자과 이상한 교수, 총학 재신임\n"
     ]
    }
   ],
   "source": [
    "print(\", \".join(eval_sets.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "손놓충 자전거 0.0012155591572123178 0.75 {16, 50, 51, 55}\n",
      "- 구성원 제보 읽다 수 습득 분실 지갑 관 카드 학생증\n",
      "- 자전거 앞 관 자물쇠 가져가다 세우다 타다 분실 타고 놓다\n",
      "- 사람 것 생각 않다 그 말 저 나 아니다 내\n",
      "- 수업 분 혹시 교수 어떻다 카이스트 수 보다 시험 들다\n",
      "퀴어 퍼레이드 0.0012155591572123178 0.75 {7, 81, 51, 55, 62}\n",
      "- 학 복위 사이즈 잠 롱패딩 교환 받다 분 구매 언제\n",
      "- 혐오 퍼레이드 퀴어 발언 준글 자위 자도 동성애 대해 꾸다\n",
      "- 사람 것 생각 않다 그 말 저 나 아니다 내\n",
      "- 수업 분 혹시 교수 어떻다 카이스트 수 보다 시험 들다\n",
      "- 대전 카 글 익명 댓글 올라오다 복합 것 사람 관련\n",
      "전자과 이상한 교수 0.0012155591572123178 0.75 {51, 55}\n",
      "- 사람 것 생각 않다 그 말 저 나 아니다 내\n",
      "- 수업 분 혹시 교수 어떻다 카이스트 수 보다 시험 들다\n",
      "총학 재신임 0.0012155591572123178 0.75 {38, 7, 51, 55, 62}\n",
      "- 학 간부 자삭 답정 정중 신임 링 필터 찬성 해달라다\n",
      "- 학 복위 사이즈 잠 롱패딩 교환 받다 분 구매 언제\n",
      "- 사람 것 생각 않다 그 말 저 나 아니다 내\n",
      "- 수업 분 혹시 교수 어떻다 카이스트 수 보다 시험 들다\n",
      "- 대전 카 글 익명 댓글 올라오다 복합 것 사람 관련\n"
     ]
    }
   ],
   "source": [
    "for key, posts in eval_sets.items():\n",
    "    precisions, recalls = [], []\n",
    "    clusters = set()\n",
    "    for post in posts:\n",
    "        cluster = tfidf_ntc.id2cluster[post]\n",
    "        clusters.add(cluster)\n",
    "        posts_in_cluster = tfidf_ntc.cluster2id[cluster]\n",
    "        precision, recall = evaluate(posts_in_cluster, eval_sets[\"전자과 이상한 교수\"])\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "#     print(key, precisions / len(posts), recalls / len(posts), clusters)\n",
    "    print(key, max(precisions), max(recalls), clusters)\n",
    "    for cluster in list(clusters):\n",
    "        clusters = [c[0] for c in tfidf_ntc.get_cluster_keywords(cluster)][:10]\n",
    "        print(\"-\", \" \".join(clusters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
